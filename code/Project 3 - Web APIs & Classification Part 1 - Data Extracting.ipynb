{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 3: Web APIs & Classification Part 1 - Data Extracting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data obtained from webscraping, to train a classifier to predict which subreddit a given post came from.\n",
    "\n",
    "I will be scraping data from www.reddit.com. 2 subreddit will be selected and 1000 posts(each) will be scraped. The data from the post will then be fed to classifier models for training and to used to predict the subreddit which the testing post is from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:04:52.493402Z",
     "start_time": "2019-10-24T16:04:50.448793Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection / Web Scaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected subreddits are Parenting and Childfree.<br>\n",
    "<br>\n",
    "Parenting subreddit discusses mainly on the issues pertaining to raising a child. Childfree mainly discusses events that prompts people not to have child. These 2 subreddit shares many similar words but the context is different. Target to scape 1000 posts from each subreddit. These will be further split into training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parenting subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new.json ensures we will not have issues to scape 1000 posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:04:54.105851Z",
     "start_time": "2019-10-24T16:04:52.498833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.reddit.com/r/Parenting/new.json'\n",
    "response = requests.get(url,headers={'User-agent': 'Pony Inc 1.0'}) # user-agent is required as reddit had blocked python webscaping.\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200 code represents the link is working and connection is through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel the data to a dictionary. With the dictionary, we can further dive in to self the title and post content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:04:54.113393Z",
     "start_time": "2019-10-24T16:04:54.109188Z"
    }
   },
   "outputs": [],
   "source": [
    "reddit_parenting_dict = response.json() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:04:54.120740Z",
     "start_time": "2019-10-24T16:04:54.116539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kind', 'data'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_parenting_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:04:54.127537Z",
     "start_time": "2019-10-24T16:04:54.123039Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['modhash', 'dist', 'children', 'after', 'before'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_parenting_dict['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:04:54.136924Z",
     "start_time": "2019-10-24T16:04:54.129805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My 5yo son wants to wear skirts - I don't mind but I had a few questions\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_parenting_dict['data']['children'][0]['data']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:04:54.145102Z",
     "start_time": "2019-10-24T16:04:54.140323Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My son turned 5 a few months ago. Since then we\\'ve been letting him pick his own clothes once a week. At first he would put together his existing clothes (he once picked his turtles onesie and rocked it) then asked for new clothes he saw on TV or his friends wear. Of late he\\'s been asking for female clothes, skirts especially. It\\'s mostly stuff like \"I want that skirt Emily wore on Tuesday\" which is super specific and helpful.\\n\\nI don\\'t care what he wears as long as it covers him and makes him comfy. But it\\'s there something in terms of gender identity or am I overthinking it? He hasn\\'t mentioned anything about it and I haven\\'t brought it up with him because he\\'s only a child. I think his skirts obsession is a fad and it\\'s more driven by his friends than anything else. I\\'ve not bought him any girls clothing yet and put it off by saying things like \"it\\'s cold today\" or \"you look so handsome in that shirt\".\\n\\nTo be clear, I don\\'t care how he dresses, and how he feels about his gender - but is he old enough to feel things about his gender? Will his peers mock him if he wears skirts? Will inaction on my behalf affect him negatively later? Will me complying have any effects later?\\n\\nI haven\\'t asked his pediatrician yet because I think it\\'s still early days to panic but as I\\'m writing this I feel flustered haha. Any opinions?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_parenting_dict['data']['children'][0]['data']['selftext']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title and selftext is what we require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.023138Z",
     "start_time": "2019-10-24T16:04:54.149235Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/Parenting/new.json\n",
      "3\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dmawu1\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dm7lz1\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dm1dbd\n",
      "3\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dlvg38\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dlomez\n",
      "2\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dliz90\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dlcca2\n",
      "6\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dl85dc\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dl2rc9\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dktwsd\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dkmh0h\n",
      "2\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dkelyx\n",
      "6\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dk5rpd\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_djv5og\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_djox7q\n",
      "2\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_djgr9h\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dja5lt\n",
      "5\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dj3aud\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dixa92\n",
      "6\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dips55\n",
      "6\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dihixv\n",
      "5\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dibvfx\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_di4gis\n",
      "6\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dhzotz\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dhugjc\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dhl3vr\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dhe8b2\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dh6tya\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dgyuup\n",
      "5\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dgpkkx\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dgjguc\n",
      "5\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dge41a\n",
      "3\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dg5m33\n",
      "3\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dg0rla\n",
      "2\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dfxc0j\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dfp7hb\n",
      "4\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dfi7z2\n",
      "2\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_dfbavf\n",
      "7\n",
      "https://www.reddit.com/r/Parenting/new.json?after=t3_df6pam\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "after = None\n",
    "\n",
    "for a in range(40): # each iterations only scape 25 reddit posts. 40 loops will get 1000 posts.\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "    else:\n",
    "        current_url = url + '?after=' + after #after each loop, the url will jump to the enxt page\n",
    "    print(current_url)\n",
    "    response = requests.get(current_url, headers={'User-agent': 'Pony Inc 2.0'})\n",
    "    \n",
    "    if response.status_code != 200: \n",
    "        print('Status error', response.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = response.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']] #all data under children will be scaped. These will include our title and selftext.\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,7)\n",
    "    print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the data into dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.074410Z",
     "start_time": "2019-10-24T16:09:04.026275Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(994, 99)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parenting=pd.DataFrame(posts) \n",
    "df_parenting.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check for duplicated posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.091034Z",
     "start_time": "2019-10-24T16:09:04.076808Z"
    }
   },
   "outputs": [],
   "source": [
    "df_parenting_duplicated=df_parenting[df_parenting.duplicated(subset =\"title\", \n",
    "                     keep = 'first')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.103012Z",
     "start_time": "2019-10-24T16:09:04.093376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 99)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parenting_duplicated.shape #checking for duplicated posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 duplicate posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.112342Z",
     "start_time": "2019-10-24T16:09:04.104874Z"
    }
   },
   "outputs": [],
   "source": [
    "df_parenting.drop_duplicates(subset =\"title\", #drop 2 posts as these are duplicates.\n",
    "                     keep = 'first', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.122018Z",
     "start_time": "2019-10-24T16:09:04.117247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(991, 99)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parenting.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed 2 duplicate posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.128547Z",
     "start_time": "2019-10-24T16:09:04.124405Z"
    }
   },
   "outputs": [],
   "source": [
    "df_parenting2=df_parenting[['title','selftext']] # We will only require title and the selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.183185Z",
     "start_time": "2019-10-24T16:09:04.131086Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaxing/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_parenting2['type']='parenting' #Labelling the target subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:04.188078Z",
     "start_time": "2019-10-24T16:09:04.185541Z"
    }
   },
   "outputs": [],
   "source": [
    "parenting_csv=df_parenting2.to_csv('../datasets/childfree.csv', index = False) #export to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Childfree subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:09:05.142744Z",
     "start_time": "2019-10-24T16:09:04.190936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.reddit.com/r/childfree/new.json'\n",
    "response = requests.get(url,headers={'User-agent': 'Pony Inc 1.0'})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:12:57.809139Z",
     "start_time": "2019-10-24T16:09:05.145327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/childfree/new.json\n",
      "6\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dmf5xm\n",
      "4\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dm8rf0\n",
      "3\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dm4nt1\n",
      "6\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dm188n\n",
      "4\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dlws3g\n",
      "7\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dlrzqk\n",
      "7\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dlnd9i\n",
      "5\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dlhowt\n",
      "4\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dl98lm\n",
      "2\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dl4dfm\n",
      "4\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dkw7oa\n",
      "5\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dkrjy2\n",
      "7\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dkms5h\n",
      "4\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dkg3h6\n",
      "2\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dk9h9a\n",
      "5\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dk27oa\n",
      "5\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_djv0xs\n",
      "3\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_djq1iz\n",
      "7\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_djlbyn\n",
      "7\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_djdzoz\n",
      "5\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dja9sw\n",
      "2\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dj3yoe\n",
      "2\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dizw8u\n",
      "7\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_diws81\n",
      "4\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_ditiue\n",
      "2\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dipwib\n",
      "4\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dik976\n",
      "7\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_diewax\n",
      "7\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_diak6s\n",
      "6\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_di1pql\n",
      "6\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dhtrj9\n",
      "2\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dhm9n3\n",
      "2\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dhgy0t\n",
      "5\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dhbcmv\n",
      "5\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dh4d5u\n",
      "6\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dguymh\n",
      "4\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dgii86\n",
      "2\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dgeqar\n",
      "6\n",
      "https://www.reddit.com/r/childfree/new.json?after=t3_dg7mpy\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "after = None\n",
    "\n",
    "for a in range(40):\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "    else:\n",
    "        current_url = url + '?after=' + after\n",
    "    print(current_url)\n",
    "    response = requests.get(current_url, headers={'User-agent': 'Pony Inc 2.0'})\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print('Status error', response.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = response.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,7)\n",
    "    print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:12:57.854465Z",
     "start_time": "2019-10-24T16:12:57.813972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 99)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_childfree=pd.DataFrame(posts)\n",
    "df_childfree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:12:57.864895Z",
     "start_time": "2019-10-24T16:12:57.856877Z"
    }
   },
   "outputs": [],
   "source": [
    "df_childfree_duplicated=df_childfree[df_childfree.duplicated(subset =\"title\",\n",
    "                     keep = 'first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:12:57.870387Z",
     "start_time": "2019-10-24T16:12:57.866783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 99)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_childfree_duplicated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:12:57.876694Z",
     "start_time": "2019-10-24T16:12:57.872752Z"
    }
   },
   "outputs": [],
   "source": [
    "df_childfree2=df_childfree[['title','selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:12:57.920768Z",
     "start_time": "2019-10-24T16:12:57.883506Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaxing/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_childfree2['type']='childfree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T16:12:57.929515Z",
     "start_time": "2019-10-24T16:12:57.926768Z"
    }
   },
   "outputs": [],
   "source": [
    "childfree_csv=df_childfree2.to_csv('../datasets/childfree.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data collection ends here and I will continue on part 2 with the data cleaning and modelling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
